{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "154594a5",
   "metadata": {},
   "source": [
    "# Import module\n",
    "Nhập các thư viện cần thiết như NumPy, scikit-learn để đánh giá, matplotlib để vẽ biểu đồ, và pickle để xuất. Ngoài ra, nhập DecisionTreeClassifier từ module Decision_Tree.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac7c0a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from models.Decision_Tree import DecisionTreeClassifier, load_iris_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532bca66",
   "metadata": {},
   "source": [
    "# Load data\n",
    "Sử dụng hàm load_iris_data từ module để tải bộ dữ liệu Iris từ file CSV. Chia dữ liệu thành tập huấn luyện và kiểm tra bằng train_test_split từ scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "558b8f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 120\n",
      "Test set size: 30\n"
     ]
    }
   ],
   "source": [
    "# Load data from CSV\n",
    "# Compute project root (two levels up from this notebook) so data/ is at project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "data_path = os.path.join(project_root, 'data', 'IRIS.csv')\n",
    "if not os.path.exists(data_path):\n",
    "    raise FileNotFoundError(f\"Data file not found: {data_path}\")\n",
    "X, y = load_iris_data(data_path)\n",
    "\n",
    "# Shuffle data to ensure random split\n",
    "indices = np.random.permutation(len(X))\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Split into train and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb77b7c6",
   "metadata": {},
   "source": [
    "# Train Decision Tree\n",
    "Khởi tạo DecisionTreeClassifier với các tham số cụ thể (ví dụ: max_depth, criterion). Huấn luyện mô hình trên dữ liệu tập huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fb04228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy model trained successfully!\n",
      "Gini model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Train models with both criteria\n",
    "dt_entropy = DecisionTreeClassifier(max_depth=5, criterion='entropy')\n",
    "dt_entropy.fit(X_train, y_train)\n",
    "print(\"Entropy model trained successfully!\")\n",
    "\n",
    "dt_gini = DecisionTreeClassifier(max_depth=5, criterion='gini')\n",
    "dt_gini.fit(X_train, y_train)\n",
    "print(\"Gini model trained successfully!\")\n",
    "\n",
    "# Use entropy for main predictions\n",
    "dt_classifier = dt_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcd1f88",
   "metadata": {},
   "source": [
    "# Test và đánh giá\n",
    "Thực hiện dự đoán trên dữ liệu kiểm tra. Tính toán và hiển thị các chỉ số như độ chính xác, precision, recall, và F1-score bằng các hàm của scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28e75ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENTROPY ===\n",
      "Train size: 120\n",
      "Test size : 30\n",
      "\n",
      "Sample 1: True = Iris-setosa | Predicted = Iris-setosa ✓\n",
      "Sample 2: True = Iris-setosa | Predicted = Iris-setosa ✓\n",
      "Sample 3: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 4: True = Iris-setosa | Predicted = Iris-setosa ✓\n",
      "Sample 5: True = Iris-versicolor | Predicted = Iris-versicolor ✓\n",
      "Sample 6: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 7: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 8: True = Iris-versicolor | Predicted = Iris-versicolor ✓\n",
      "Sample 9: True = Iris-setosa | Predicted = Iris-setosa ✓\n",
      "Sample 10: True = Iris-versicolor | Predicted = Iris-versicolor ✓\n",
      "Sample 11: True = Iris-setosa | Predicted = Iris-setosa ✓\n",
      "Sample 12: True = Iris-versicolor | Predicted = Iris-versicolor ✓\n",
      "Sample 13: True = Iris-versicolor | Predicted = Iris-versicolor ✓\n",
      "Sample 14: True = Iris-setosa | Predicted = Iris-setosa ✓\n",
      "Sample 15: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 16: True = Iris-setosa | Predicted = Iris-setosa ✓\n",
      "Sample 17: True = Iris-versicolor | Predicted = Iris-versicolor ✓\n",
      "Sample 18: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 19: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 20: True = Iris-versicolor | Predicted = Iris-versicolor ✓\n",
      "Sample 21: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 22: True = Iris-setosa | Predicted = Iris-setosa ✓\n",
      "Sample 23: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 24: True = Iris-setosa | Predicted = Iris-setosa ✓\n",
      "Sample 25: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 26: True = Iris-versicolor | Predicted = Iris-versicolor ✓\n",
      "Sample 27: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 28: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 29: True = Iris-versicolor | Predicted = Iris-versicolor ✓\n",
      "Sample 30: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "\n",
      "Misclassified samples:\n",
      "\n",
      "Accuracy: 100.00%\n",
      "\n",
      "==================================================\n",
      "=== GINI ===\n",
      "Sample 1: True = Iris-setosa | Predicted = Iris-setosa ✓\n",
      "Sample 2: True = Iris-setosa | Predicted = Iris-setosa ✓\n",
      "Sample 3: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 4: True = Iris-setosa | Predicted = Iris-setosa ✓\n",
      "Sample 5: True = Iris-versicolor | Predicted = Iris-versicolor ✓\n",
      "Sample 6: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 7: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 8: True = Iris-versicolor | Predicted = Iris-versicolor ✓\n",
      "Sample 9: True = Iris-setosa | Predicted = Iris-setosa ✓\n",
      "Sample 10: True = Iris-versicolor | Predicted = Iris-versicolor ✓\n",
      "Sample 11: True = Iris-setosa | Predicted = Iris-setosa ✓\n",
      "Sample 12: True = Iris-versicolor | Predicted = Iris-versicolor ✓\n",
      "Sample 13: True = Iris-versicolor | Predicted = Iris-versicolor ✓\n",
      "Sample 14: True = Iris-setosa | Predicted = Iris-setosa ✓\n",
      "Sample 15: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 16: True = Iris-setosa | Predicted = Iris-setosa ✓\n",
      "Sample 17: True = Iris-versicolor | Predicted = Iris-versicolor ✓\n",
      "Sample 18: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 19: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 20: True = Iris-versicolor | Predicted = Iris-versicolor ✓\n",
      "Sample 21: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 22: True = Iris-setosa | Predicted = Iris-setosa ✓\n",
      "Sample 23: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 24: True = Iris-setosa | Predicted = Iris-setosa ✓\n",
      "Sample 25: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 26: True = Iris-versicolor | Predicted = Iris-versicolor ✓\n",
      "Sample 27: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 28: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "Sample 29: True = Iris-versicolor | Predicted = Iris-versicolor ✓\n",
      "Sample 30: True = Iris-virginica | Predicted = Iris-virginica ✓\n",
      "\n",
      "Misclassified samples:\n",
      "\n",
      "Accuracy: 100.00%\n",
      "\n",
      "==================================================\n",
      "=== SO SÁNH ===\n",
      "Entropy Accuracy: 100.00%\n",
      "Gini Accuracy: 100.00%\n",
      "Cả hai tương đương.\n"
     ]
    }
   ],
   "source": [
    "# Test both models\n",
    "print(\"=== ENTROPY ===\")\n",
    "y_pred_entropy = dt_entropy.predict(X_test)\n",
    "\n",
    "print(f\"Train size: {len(X_train)}\")\n",
    "print(f\"Test size : {len(X_test)}\")\n",
    "print()\n",
    "\n",
    "for i, (true, pred) in enumerate(zip(y_test, y_pred_entropy), 1):\n",
    "    status = \"✓\" if true == pred else \"✗\"\n",
    "    print(f\"Sample {i}: True = {true} | Predicted = {pred} {status}\")\n",
    "\n",
    "print(\"\\nMisclassified samples:\")\n",
    "for i, (true, pred, x) in enumerate(zip(y_test, y_pred_entropy, X_test), 1):\n",
    "    if true != pred:\n",
    "        print(f\"Sample {i}: Features = {x}, True = {true}, Pred = {pred}\")\n",
    "\n",
    "acc_entropy = accuracy_score(y_test, y_pred_entropy)\n",
    "print(f\"\\nAccuracy: {acc_entropy:.2%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== GINI ===\")\n",
    "y_pred_gini = dt_gini.predict(X_test)\n",
    "\n",
    "for i, (true, pred) in enumerate(zip(y_test, y_pred_gini), 1):\n",
    "    status = \"✓\" if true == pred else \"✗\"\n",
    "    print(f\"Sample {i}: True = {true} | Predicted = {pred} {status}\")\n",
    "\n",
    "print(\"\\nMisclassified samples:\")\n",
    "for i, (true, pred, x) in enumerate(zip(y_test, y_pred_gini, X_test), 1):\n",
    "    if true != pred:\n",
    "        print(f\"Sample {i}: Features = {x}, True = {true}, Pred = {pred}\")\n",
    "\n",
    "acc_gini = accuracy_score(y_test, y_pred_gini)\n",
    "print(f\"\\nAccuracy: {acc_gini:.2%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== SO SÁNH ===\")\n",
    "print(f\"Entropy Accuracy: {acc_entropy:.2%}\")\n",
    "print(f\"Gini Accuracy: {acc_gini:.2%}\")\n",
    "if acc_entropy > acc_gini:\n",
    "    print(\"Entropy tốt hơn.\")\n",
    "elif acc_gini > acc_entropy:\n",
    "    print(\"Gini tốt hơn.\")\n",
    "else:\n",
    "    print(\"Cả hai tương đương.\")\n",
    "\n",
    "# Use entropy for main predictions (for export)\n",
    "y_pred = y_pred_entropy\n",
    "accuracy = acc_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dafde9",
   "metadata": {},
   "source": [
    "# Biểu đồ đánh giá hiệu suất mô hình\n",
    "Vẽ biểu đồ cột so sánh độ chính xác của mô hình Entropy và Gini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76361015",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Set seaborn style for better aesthetics\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43msns\u001b[49m.set_style(\u001b[33m\"\u001b[39m\u001b[33mwhitegrid\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Bar chart for accuracy comparison\u001b[39;00m\n\u001b[32m      5\u001b[39m criteria = [\u001b[33m'\u001b[39m\u001b[33mEntropy\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mGini\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "# Set seaborn style for better aesthetics\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Bar chart for accuracy comparison\n",
    "criteria = ['Entropy', 'Gini']\n",
    "accuracies = [acc_entropy, acc_gini]\n",
    "\n",
    "plt.figure(figsize=(10, 6))  # Increased size for better visibility\n",
    "palette = sns.color_palette(\"Set2\", len(criteria))\n",
    "bars = plt.bar(criteria, accuracies, color=palette)\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "plt.title('So sánh độ chính xác của mô hình Decision Tree', fontsize=16, fontweight='bold')\n",
    "plt.xticks(rotation=0, fontsize=12)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, f'{acc:.2%}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Classification report comparison with grouped bar chart\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision_e, recall_e, f1_e, _ = precision_recall_fscore_support(y_test, y_pred_entropy, average='weighted')\n",
    "precision_g, recall_g, f1_g, _ = precision_recall_fscore_support(y_test, y_pred_gini, average='weighted')\n",
    "\n",
    "metrics = ['Precision', 'Recall', 'F1-Score']\n",
    "entropy_metrics = [precision_e, recall_e, f1_e]\n",
    "gini_metrics = [precision_g, recall_g, f1_g]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))  # Increased size for better visibility\n",
    "palette = sns.color_palette(\"Set2\", 2)\n",
    "bars1 = ax.bar(x - width/2, entropy_metrics, width, label='Entropy', color=palette[0], alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, gini_metrics, width, label='Gini', color=palette[1], alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('So sánh các chỉ số hiệu suất (Precision, Recall, F1)', fontsize=16, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics, fontsize=12)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, height + 0.01, f'{height:.2f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9e1965",
   "metadata": {},
   "source": [
    "# Xuất mô hình đã huấn luyện\n",
    "Sử dụng pickle để serialize và lưu mô hình đã huấn luyện dưới dạng file .pkl trong thư mục src/models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ece5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to c:\\Project\\MachineLearning\\ML_Team4_IrisFlowers\\src\\models\\decision_tree.pkl\n"
     ]
    }
   ],
   "source": [
    "# Export the model\n",
    "model_path = os.path.join(os.getcwd(), 'models', 'decision_tree.pkl')\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(dt_classifier, f)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a37583",
   "metadata": {},
   "source": [
    "# Nhập mô hình đã xuất\n",
    "Sử dụng pickle để load mô hình từ file .pkl đã lưu và kiểm tra dự đoán trên dữ liệu mới."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce73d45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Loaded model accuracy: 0.93\n",
      "Predictions match: True\n"
     ]
    }
   ],
   "source": [
    "# Import the model\n",
    "with open(model_path, 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Test prediction with loaded model\n",
    "loaded_predictions = loaded_model.predict(X_test)\n",
    "loaded_accuracy = accuracy_score(y_test, loaded_predictions)\n",
    "print(f\"Loaded model accuracy: {loaded_accuracy:.2f}\")\n",
    "\n",
    "# Compare with original predictions\n",
    "print(f\"Predictions match: {np.array_equal(y_pred, loaded_predictions)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
